{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37db5b6e-bd68-4900-be0e-88e7ac19afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir ~/.kaggle\n",
    "# !mv kaggle.json ~/.kaggle/kaggle.json\n",
    "# !pip3 install kaggle\n",
    "# !kaggle datasets download -d imran2002/imagenet-top50-400train-50val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393d12ae-db00-4fa3-b561-1f775faa0ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get update\n",
    "# !apt-get install p7zip-full -y\n",
    "!7z x data_raw.zip -odata/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c0d0f2-863d-4758-9329-d41a6dd46f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/imrnh/beyond_intuition_code.git\n",
    "# !cp -r beyond_intuition_code/* /workspace/\n",
    "# !rm -rf beyond_intuition_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca647e1-18c6-4219-9c44-69ee9e26f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install h5py einops tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f04737f-7469-4097-bcf7-cb640ff8cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be50108-03cd-479e-b3b9-401b5d116797",
   "metadata": {},
   "source": [
    "# **Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7669c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embd_to_class(self, batched_embed):\n",
    "    class_indices = []\n",
    "    for embd in batched_embed:\n",
    "        cls_idx = torch.argmax(embd)\n",
    "        class_indices.append(cls_idx)\n",
    "    return torch.Tensor(class_indices)\n",
    "\n",
    "def measure_accuracy(self, yhat, y):\n",
    "    yhat_idx = self.embd_to_class(yhat)\n",
    "\n",
    "    accuracy = 0.0\n",
    "    for yh, yval in zip(yhat_idx, y):\n",
    "        accuracy += 1 if (yh == yval) else 0\n",
    "        \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def callbacks(t_loss, v_loss, vacc, epoch, train_logs):\n",
    "    if epoch > 1:\n",
    "        prev_vl = train_logs[-2]['val_loss']\n",
    "        prev_vacc = train_logs[-2]['val_accuracy']\n",
    "\n",
    "        if vacc >= prev_vacc :\n",
    "            save_model(f\"raw_images_{str(epoch)}_max_validation_accuracy\")\n",
    "            print(f\"Saved for acc:{vacc}\")\n",
    "\n",
    "        if v_loss <= prev_vl :\n",
    "            save_model(f\"raw_images_{str(epoch)}_min_validation_loss\")\n",
    "            print(f\"Saved for loss: {v_loss}\")\n",
    "\n",
    "    return train_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b0c05a-20f1-4752-bc1f-85af719469b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Train the models for given saliency map.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "from utils.model_loaders import vit_base_patch16_224\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, data_path, epochs, batch_size, num_workers, lr, weight_decay) -> None:\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        self.save_dir = \"custom_trained_models/\"\n",
    "        self.data_path = data_path\n",
    "        self.train_logs = []\n",
    "\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        # Model, Optimizer and Loss function setup\n",
    "        self.model = vit_base_patch16_224(pretrained=False, num_classes=50).cuda()\n",
    "\n",
    "        self.optimizer = Adam(self.model.parameters(), lr=self.lr, weight_decay=weight_decay)\n",
    "        self.criterion = CrossEntropyLoss()\n",
    "\n",
    "        # Data loading and transforms\n",
    "        self.image_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ])\n",
    "\n",
    "        self.dataset = datasets.ImageFolder(root=self.data_path + \"/train\", transform=self.image_transform)\n",
    "        self.dataloader = DataLoader(self.dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, drop_last=False)\n",
    "\n",
    "        self.validation_dataset = datasets.ImageFolder(root=self.data_path + \"/val\", transform=self.image_transform)\n",
    "        self.validation_dataloader = DataLoader(self.validation_dataset, batch_size=int(self.batch_size / 4), shuffle=False, num_workers=self.num_workers, drop_last=False)\n",
    "    \n",
    "        print(f\"{len(self.dataloader) * batch_size } Train Images found\")\n",
    "        print(f\"{len(self.validation_dataloader) * batch_size} Validation Images found\")\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "        Train the model and finally save it.\n",
    "    \"\"\"\n",
    "    def train(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss, val_loss, val_accuracy = 0.0, 0.0, 0.0\n",
    "\n",
    "            for batch in tqdm(self.dataloader):  # Training\n",
    "                x, y = batch \n",
    "                x, y = x.cuda(), y.cuda()\n",
    "                y_hat = self.model(x)\n",
    "                loss = self.criterion(y_hat, y)\n",
    "                train_loss += loss.detach().cpu().item() / len(self.dataloader)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()  # backprop calculation\n",
    "                self.optimizer.step()  # Updating the weight based on these calculation.\n",
    "\n",
    "\n",
    "            for batch in tqdm(self.validation_dataloader):  # Validation\n",
    "                x_val, y_val = batch\n",
    "                x_val, y_val = x_val.cuda(), y_val.cuda()\n",
    "                pred = self.model(x_val)\n",
    "                vloss = self.criterion(pred, y_val)\n",
    "                \n",
    "                val_loss += vloss.detach().cpu().item() / len(self.validation_dataloader)\n",
    "                val_accuracy += self.measure_accuracy(pred, y_val) / len(self.validation_dataloader)\n",
    "                \n",
    "            self.callbacks(train_loss, val_loss, val_accuracy, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f109a9d-b4af-4b58-b904-264fb4e2a31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20160 Train Images found\n",
      "10176 Validation Images found\n"
     ]
    }
   ],
   "source": [
    "trainer = ModelTrainer(data_path=\"data\", epochs=50, batch_size=192, num_workers=100, lr=0.0001, weight_decay=0.00004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff7a374-b89c-433b-b035-0f7ce6db9aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6448f87a-aef9-4d56-bfb0-e424886cc821",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bd3bf1-ab37-4b25-8c9f-a6d9206f7e59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
