{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14446c78-5b46-49c7-86e9-eb1207bf4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37db5b6e-bd68-4900-be0e-88e7ac19afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir ~/.kaggle\n",
    "# !mv kaggle.json ~/.kaggle/kaggle.json\n",
    "# !pip3 install kaggle\n",
    "# !kaggle datasets download -d imran2002/imagenet-top50-400train-50val\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "393d12ae-db00-4fa3-b561-1f775faa0ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get update\n",
    "# !apt-get install p7zip-full -y\n",
    "# !7z x imagenet-top50-400train-50val.zip -odata/\n",
    "# !rm imagenet-top50-400train-50val\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26c0d0f2-863d-4758-9329-d41a6dd46f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/imrnh/beyond_intuition_code.git\n",
    "# !cp -r beyond_intuition_code/* /workspace/\n",
    "# !rm -rf beyond_intuition_code\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ca647e1-18c6-4219-9c44-69ee9e26f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install h5py einops tqdm\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f04737f-7469-4097-bcf7-cb640ff8cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be50108-03cd-479e-b3b9-401b5d116797",
   "metadata": {},
   "source": [
    "# **Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "423c1b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f04ddbb57b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "from utils.trainer_callback import Callback\n",
    "from utils.model_loaders import vit_base_patch16_224\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7669c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embd_to_class(batched_embed):\n",
    "    class_indices = []\n",
    "    for embd in batched_embed:\n",
    "        cls_idx = torch.argmax(embd)\n",
    "        class_indices.append(cls_idx)\n",
    "    return torch.Tensor(class_indices)\n",
    "\n",
    "def measure_accuracy(yhat, y):\n",
    "    yhat_idx = embd_to_class(yhat)\n",
    "\n",
    "    accuracy = 0.0\n",
    "    for yh, yval in zip(yhat_idx, y):\n",
    "        accuracy += 1 if (yh == yval) else 0\n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0b0c05a-20f1-4752-bc1f-85af719469b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, data_path, epochs, batch_size, val_batch_size ,num_workers, lr, weight_decay) -> None:\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        self.data_path = data_path\n",
    "        self.callbacks = Callback(\"train_logs.txt\", \"custom_trained_models/\", True, True, False, 0, 0)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        # Model, Optimizer and Loss function setup\n",
    "        self.model = vit_base_patch16_224(pretrained=False, num_classes=50).cuda()\n",
    "\n",
    "        self.optimizer = Adam(self.model.parameters(), lr=self.lr, weight_decay=weight_decay)\n",
    "        self.criterion = CrossEntropyLoss()\n",
    "\n",
    "        # Data loading and transforms\n",
    "        self.image_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ])\n",
    "\n",
    "        self.dataset = datasets.ImageFolder(root=self.data_path + \"/train\", transform=self.image_transform)\n",
    "        self.dataloader = DataLoader(self.dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, drop_last=False)\n",
    "\n",
    "        self.validation_dataset = datasets.ImageFolder(root=self.data_path + \"/val\", transform=self.image_transform)\n",
    "        self.validation_dataloader = DataLoader(self.validation_dataset, batch_size= val_batch_size, shuffle=False, num_workers=self.num_workers, drop_last=False)\n",
    "    \n",
    "        print(f\"{len(self.dataloader) * batch_size } Train Images found\")\n",
    "        print(f\"{len(self.validation_dataloader) * val_batch_size} Validation Images found\")\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "        Train the model and finally save it.\n",
    "    \"\"\"\n",
    "    def train(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss, val_loss, val_accuracy = 0.0, 0.0, 0.0\n",
    "\n",
    "            for batch in tqdm(self.dataloader):  # Training\n",
    "                x, y = batch \n",
    "                x, y = x.cuda(), y.cuda()\n",
    "                y_hat = self.model(x)\n",
    "                loss = self.criterion(y_hat, y)\n",
    "                train_loss += loss.detach().cpu().item() / len(self.dataloader)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()  # backprop calculation\n",
    "                self.optimizer.step()  # Updating the weight based on these calculation.\n",
    "\n",
    "\n",
    "            for batch in tqdm(self.validation_dataloader):  # Validation\n",
    "                x_val, y_val = batch\n",
    "                x_val, y_val = x_val.cuda(), y_val.cuda()\n",
    "                pred = self.model(x_val)\n",
    "                vloss = self.criterion(pred, y_val)\n",
    "                \n",
    "                val_loss += vloss.detach().cpu().item() / len(self.validation_dataloader)\n",
    "                val_accuracy += measure_accuracy(pred, y_val) / len(self.validation_dataloader)\n",
    "                \n",
    "            self.callbacks.__call__(self.model, \"r\", epoch, \n",
    "                                    {'train_loss': train_loss, 'validation_loss': val_loss, 'validation_accuracy': val_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f109a9d-b4af-4b58-b904-264fb4e2a31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20064 Train Images found\n",
      "2512 Validation Images found\n"
     ]
    }
   ],
   "source": [
    "trainer = ModelTrainer(data_path=\"data\", epochs=50, batch_size=96, val_batch_size=16, num_workers=50, lr=0.001, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff7a374-b89c-433b-b035-0f7ce6db9aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9816c0310b5843038940ee7b89bd8913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.0, 'validation_loss': 4.077100434880348, 'validation_accuracy': 0.3375796178343949}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99fd0e441ae4fc9b6ef79f7c93ec92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 0.0, 'validation_loss': 4.077100434880348, 'validation_accuracy': 0.3375796178343949}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecdfd892770041be8a3353cda10fcb26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bd3bf1-ab37-4b25-8c9f-a6d9206f7e59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
